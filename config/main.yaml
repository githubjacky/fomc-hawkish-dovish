defaults:
  - _self_

mode: tune

flair_embed:
  model_name: bert-base-uncased
  flair_layers: all
  flair_layer_mean: true

sbert_embed:
  model_name: sentence-transformers/all-mpnet-base-v2 

nn: GRU
# should adjust only in sentence-level classification
# for word-level, flair's word embeddings is the only choice
embed_framework: flair
lr: 0.0003
batch_size: 64
random_state: 1126

early_stop:
  monitor: val/macro_avg_prec
  mode: max
  patience: 20

model_check_point:
  monitor: val/macro_avg_prec
  mode: max

trainer:
  accelerator: gpu
  strategy: auto
  devices:
    - 1
  num_nodes: 1
  precision: 32-true
  max_epochs: 1000
  log_every_n_steps: 1
  check_val_every_n_epoch: 3
  # accumulate_grad_batches:
  # gradient_clip_val:

tuning:
  study_name: bert_base_embed_gru_dropout_last_ff
  n_trials: 100

RNNFamily:
  hidden_size: 128
  num_layers: 2
  dropout: 0.3
  bidirectional: True

MLP:
  hidden_size: 256
  n_layers: 1
  dropout: 0.2
  output_size: 128

ff:
  hidden_size: 
  dropout: 